#set document(title: "Аппаратное обеспечение вычислительных систем")

#set text(lang: "ru")

#show link: set text(fill: blue)
#show raw.where(block: true): (it) => block(stroke: (0.5pt + gray), width: 100%, radius: 4pt, inset: 8pt, it)

#title()
#outline()
#place(bottom + center, float: true, dy: 2.5cm)[
  #link("https://itmo.arslee.me")[itmo.arslee.me]
  #image("assets/icon.png", height: 12%)
]
#pagebreak()

#set page(numbering: "1")
#counter(page).update(1)

= Кодирование беззнаковых целых чисел

Компьютер оперирует _байтами_ --- минимальными адресуемыми ячейками памяти. Практически у всех современных компьютеров 1 байт равен 8 бит, хотя раньше существовали архитектуры, где 1 байт был равен, например, 7 бит.

Рассмотрим схему:

#align(center)[
  #table(columns: 8, rows: 3,
    align: center + horizon,
    inset: (x, y) => if (y == 0) { (x: 0pt, y: 8pt) } else { 8pt }, 
    stroke: (x, y) => if (y == 1) { (x: 1pt, y: 1pt) },
    [MSB],[],[],[],[],[],[],[LSB],
    [0],[1],[1],[1],[1],[0],[1],[1],
    [$2^7$], [$2^6$], [$2^5$], [$2^4$], [$2^3$], [$2^2$], [$2^1$], [$2^0$],
  )
]

Каждая ячейка соответсвует биту. У каждого бита есть свой "вес", равный показателю степени двойки --- основания системы счисления компьютера.

Поскольку машина оперирует байтами, то нельзя сказать что-то вроде "первый бит" или "последний бит". Для компьютера это не имеет значения. Так что принято говорить "младший бит" (LSB, Least Significant Bit) или "старший бит" (MSB, Most Significant Bit).

Декодируем число из схемы. Каждый бит ячейки умножается на его вес, а затем все складывается. В итоге имеем $2^6+2^5+2^4+2^3+2^1+2^0 = 123$.

Диапазон значений равен $[0; space 2^n - 1]$. Например, для 8 бит это $[0; 255]$.

В языке Си гарантируется модулярная арифметика для беззнаковых чисел. Это означает, что выражение вида "`uint8_t a = 254 + 7`" будет равно `5`, то есть возьмется по модулю `256`.

= Кодирование знаковых целых чисел

Машина не знает про знак числа, находящегося в памяти. Представление знакового числа --- забота самого программиста.

== Прямой код

Самый очевидный способ закодировать число --- выделить старший бит под знак. Причем 0 обозначает "+", а 1 обозначает "-", чтобы можно было легко преобразовать беззнаковые числа в знаковые.

На примере числа -106:

#align(center)[
  #table(columns: 8, rows: 2,
    align: center + horizon,
    inset: 8pt,
    stroke: (x, y) => if (y == 0) { (x: 1pt, y: 1pt) },
    [1],[1],[1],[0],[1],[0],[1],[0],
    [$plus.minus$], [$64$], [$32$], [$16$], [$8$], [$4$], [$2$], [$1$],
  )
]

Имеем, что беззнаковое число 234 в прямом коде интерпретируется как -106.

Диапазон равен $[-2^(n-1) + 1; space 2^(n-1) - 1]$. Например, для 8-битного числа это $[-127; 127]$

У прямого кода есть проблемы:
+ Существования числа $-0$.
+ Трудности с выполнением арифметических операций.
+ Нет зацикливания. Хотим, чтобы $127 + 1$ было равно $-127$, но вместо этого получим $-0$.

== Обратный код

В зарубежных источниках именуется как "дополнение до 1" (1's complement).

Идея в том, чтобы старший бит интерпретировать как число, равное сумме всех младших весов, взятое со знаком "минус". То есть, для 8-битного числа старший бит будет интерпретироваться как $-127$.

На примере числа $-34$:

#align(center)[
  #table(columns: 8, rows: 2,
    align: center + horizon,
    inset: 8pt,
    stroke: (x, y) => if (y == 0) { (x: 1pt, y: 1pt) },
    [1],[1],[0],[1],[1],[1],[0],[1],
    [$-127$], [$64$], [$32$], [$16$], [$8$], [$4$], [$2$], [$1$],
  )
]

Имеем, что беззнаковое число $221$ в обратном коде интерпретируется как -34.

Данное кодирование называется "обратным кодом", поскольку для взятия обратного числа нужно просто инвертировать все биты.

Диапазон равен $[-2^(n-1) + 1; space 2^(n-1) - 1]$. Например, для 8-битного числа это $[-127; 127]$.

Плюсы обратного кода:
- Симметричный диапазон.
- Имеется зацикливание! Для 8-битного числа, $127+1 = -127$.
- Сумма/разность двух чисел тривиальна и аналогична беззнаковым числам.

Проблемой остается число $-0$.

== Дополнительный код

В зарубежных источниках именуется как "дополнение до 2" (2's complement).

Идея схожа с обратным кодом, но старший бит теперь равен сумме всех младших весов _плюс единица_, взятого со знаком "минус". Например, для 8-битного числа старший бит интерпретируется как $-128$.

На примере числа $-107$:

#align(center)[
  #table(columns: 8, rows: 2,
    align: center + horizon,
    inset: 8pt,
    stroke: (x, y) => if (y == 0) { (x: 1pt, y: 1pt) },
    [1],[0],[0],[1],[0],[1],[0],[1],
    [$-128$], [$64$], [$32$], [$16$], [$8$], [$4$], [$2$], [$1$],
  )
]

Беззнаковое число 181 интерпретируется в дополнительном коде как $-107$.

Взятие отрицания работает в два шага:
1. Инверсия всех битов
2. Добавление единицы с отбрасыванием последнего переноса

Диапазон равен $[-2^(n-1); space 2^(n-1) - 1]$. Для

Дополнительный код имеет следующие плюсы:
- Имеется зацикливание.
- Числа $-0$ нет!
- Сложение и вычитание чисел тривиально.
  - Для умножения чисел в дополнительном коде существует алгоритм Бута.

Единственный минус --- несимметричный диапазон. Если взять отрицание от 8-битного числа $-128$, то получится $-128$.

Практически все современные системы представляют знаковые числа в дополнительном коде.

== Всякие экзотические коды

=== "Чередующийся" код

Идея в том, чтобы выделить _младший_ бит под знак:

$
  000_2 |-> 0 wide 001_2 |-> -1 wide 010_2 |-> 1 wide 011_2 |-> -2 wide ...
$

Используется для кодирования чисел произвольной длины. Арифметика над данным кодом невозможна.

=== Основание -2

Вес каждого бита --- это степень числа $-2$.

На примере числа $-107$:

#align(center)[
  #table(columns: 8, rows: 2,
    align: center + horizon,
    inset: (x: 2pt, y: 10pt),
    stroke: (x, y) => if (y == 0) { (x: 1pt, y: 1pt) },
    [1],[0],[0],[1],[0],[1],[0],[1],
    [$(-2)^7$], [$(-2)^6$], [$(-2)^5$], [$(-2)^4$], [$(-2)^3$], [$(-2)^2$], [$(-2)^1$], [$(-2)^0$],
  )
]

Диапазон в случае 8 бит равен $[-170; 85]$. Число 0 кодируется однозначно!

== Немного про Си, UB, оптимизации и всякое такое

_UB, Undefined Behavior --- "неопределенное поведение"._

Когда делали стандарт Си, основной упор был на переносимость языка между различными архитектурами.

Стандарт ISO C не диктует формат хранения знаковых чисел. Более того, диапазоны знаковых типов симметричны, что позволяет использовать хоть прямой код. Например, для `int16_t` диапазон равен $[-32767; 32767]$. То есть число $-32768$ (в допкоде) --- это UB!

Более того, в стандарте не написано, что знаковые числа должны зацикливаться. Так что "`INT_MAX + 123`" --- тоже UB.

Но все современное железо использует и допкод, и модулярную арифметику. Почему бы просто не игнорировать UB? Проблема в том, что UB для компилятора означает что-то вроде "могу сделать что захочу", из-за чего может прийти к некорректным оптимизациям. Например, заменить цикл `for (int8_t i = 1; i > 0; i++)` на `while (1)`.

Но несколько лет назад комитет по стандартизации Си все же решили признать современные реалии, а потому закрепили в стандарте C23 и дополнительный код, и модулярную арифметику для знаковых чисел.

= Числа с фиксированной точкой

Допустим, мы хотим записать $12.34$ рубля, но в нашем распоряжении только целые числа. Не беда, будем просто хранить 1234 копейки.

Аналогичный пример из повседневной жизни --- проценты. Например, число $45.67$ можно записать в процентах как $4567$. То есть, целое число --- это множитель к дроби $1/100$.

Идея чисел с фиксированной точкой такая же: целое число интерпретируется как множитель к некоторой дроби.

Возьмем в качестве примера все те же 8 бит, но сделаем веса немного по-другому:

#align(center)[
  #table(columns: 8, rows: 2,
    align: center + horizon,
    inset: (x, y) => if (y == 1) { (x: 0pt, y: 8pt) } else { 8pt },
    stroke: (x, y) => if (y == 0) { (x: 1pt, y: 1pt) },
    [0],[1],[1],[1],[1],[0],[1],[1],
    [$2^3$], [$2^2$], [$2^1$], [$2^0$], [$2^(-1)$], [$2^(-2)$], [$2^(-3)$], [$2^(-4)$],
  )
]

Старшие 4 бита теперь означают целую часть, а младшие 4 бита --- дробную. В итоге мы закодировали число $7.6875$.

В общем случае, число с фиксированной точкой имеет вид $n' = n dot 2^(-b)$, где:
- $n$ --- целое число
- $b$ --- число бит под дробную часть

Действительно, для нашего примера:
- $n = 123$
- $b = 4$
- $n' = 123 dot 2^(-4) = 7.6875$.

Ничто не мешает выделить, например, 7 бит под целую часть и 1 бит под дробную, или наоборот. Более того, можно сделать число знаковым с помощью любого удобного кода (в т.ч. де-факто стандартный дополнительный код).

Для обозначения чисел с фиксированной точкой принято обозначение `QA.B`, где:
- `A` --- количество бит под целую часть
- `B` --- количество бит под дробную часть

Для примера выше, формат обозначается как `Q4.4`.

В данном документе мы отбросим букву `Q` и будем просто обозначать число как `A.B`.

== Перевод десятичной дроби в двоичную в столбик

Алгоритм:
1. В правом столбце запишем дробную часть
2. Умножаем дробную часть на 2.
3. В левый столбец записываем целую часть, в правый столбец записываем дробную часть.
4. Повторяем процесс с шага 2 нужное количество раз
5. Выписываем биты из левого столбца сверху вниз

На примере $0.675$:

#align(center)[
  #table(
    columns: 2,
    align: center + horizon,
    stroke: (x, y) => if (x == 0) { (right: 1pt) } + if (y == 0) { (bottom: 1pt) },
    [], [625],
    [1], [25],
    [0], [5],
    [1], [0],
  )
]

Итак, $0.675 = 0.101_2$.

Алгоритм был таков:
1. $0.625 dot 2 = 1.25$. Пишем 1 справа, 25 слева.
2. $0.25 dot 2 = 0.5$. Пишем 0 справа, 5 слева.
3. $0.5 dot 2 = 1$. Пишем 1 справа, 0 слева.
4. Выписываем сверху вниз правый столбец: 101. Это и есть двоичная запись десятичной дроби.

== Периодическая двоичная дробь

Попробуем перевести число $0.1$ в двоичное в столбик:

#align(center)[
  #table(
    columns: 2,
    align: center + horizon,
    stroke: (x, y) => if (x == 0) { (right: 1pt) } + if (y == 0) { (bottom: 1pt) },
    [], [1],
    [0], [2],
    [0], [4],
    [0], [8],
    [1], [6],
    [1], [2],
    [0], [4],
    [0], [8],
    [1], [6],
    [1], [2],
    [...], [...],
  )
]

В итоге получаем периодическую дробь: $0.1 = 0.0(0011)_2$.

Это говорит о том, что не всякое десятичное число можно закодировать как число с фиксированной точкой без потери точности.

== Немного про побитовые сдвиги в Си

В Си существует две различные по поведению операции побитового сдвига: логический и арифметический.

=== Логический сдвиг

Определен для беззнаковых целых чисел.

- *Сдвиг вправо*. Переносим все биты на $n$ разрядов вправо. При этом младшие $n$ бит пропадают. Заметим, что это эквивалентно делению на $2^n$ с округлением к нулю. Пример:

  ```c
  (0b1101 >> 2) == 0b11
  ```

- *Сдвиг влево*. Переносим все биты на $n$ разрядов влево. "Освободившиеся" младшие $n$ бит заполняем нулями. Заметим, что это эквивалентно умножению на $2^n$. Пример:

  ```c
  (0b1101 << 3) == 0b1101000
  ```

=== Арифметический сдвиг

Определен для знаковых целых чисел.

- *Сдвиг вправо*. Сдвигаем биты на `n` разрядов вправо, "освободившиеся" места заполняем старшим битом исходного числа. Это эквивалентно делению на $2^n$, но _с округлением к $-oo$_. Пример:

  ```c
  -3 << 2 == -1
  ```

- *Сдвиг влево*. Эквивалентно логическому сдвигу влево.

== Арифметические операции

Пусть нам даны два числа с фиксированной точкой в одинаковом формате:

```c
uint32_t a = ...;  // 16.16
uint32_t b = ...;  // 16.16
```

=== Сложение и вычитание

Просто берем и складываем/вычитаем два числа. Модулярная арифметика работает без проблем.

```c
uint32_t sum = a + b;
uint32_t diff = a - b;
```


=== Умножение

Здесь сложнее. Вспомним аналогию с процентами. Умножим $40%$ на $50%$. Очевидно, что $2000%$ тут не подойдет, а значит нам нужно "сдвинуть" число, поделив на 100 и получив в итоге $20%$.

Распишем умножение алгебраически:

$
  a' dot b' = (a dot 2^(-16)) dot (b dot 2^(-16)) = (a dot b) dot 2^(-32)
$

Как можно видеть, теперь у нас 32 бита под дробную часть! Надо привести обратно к 16, сдвинув число на 16 бит вправо. Еще надо учесть, что произведение может не поместиться в текущий тип, так что надо расширять размерность.

Итак, учитывая все вышеперечисленное, код выглядит так:

```c
uint64_t mul = ((uint64_t)a * b) >> 16;
```

Стоит понимать, что, отбросив дробных 16 бит, мы потеряли точность, так что нужно производить округление.

=== Деление

Снова аналогия с процентами. Очевидно, что $40% div 50% != 0.8%$. Поэтому предварительно умножим делимое на 100, что и даст нам корректные $80%$.

Посмотрим на алгебраическое представление:

$
  a' / b' = (a dot 2^(-16)) / (b dot 2^(-16)) = a / b
$

Под дробную часть теперь 0 бит! Так быть не должно. Предварительно сдвинем $a'$ влево на $16$ бит:

$
  (a' dot 2^(-16)) / b' = (a dot 2^(-32)) / (b dot 2^(-16)) = a / b dot 2^(-16)
$

Теперь то, что надо.

В коде деление выглядит так:

```c
uint32_t div = ((uint64_t)a << 16) / b;
```

Деление происходит нацело, отчего теряется точность. Надо делать округление.

== Округления

При умножении или делении мы вынуждены округлять наши результаты. Рассмотрим основные способы.

=== К нулю

По сути отбрасывание разрядов. На числовой прямой, округленное число становится ближе к нулю. Примеры:

$
  2.6 -> 2 wide -3.4 -> -3
$

=== К $-oo$

Если число положительное, отбрасываем разряды. Если отрицательное, то округляем к младшему числу. На числовой прямой, числа сдвигаются влево, к $-oo$. Примеры:

$
  3.8 -> 3 wide -3.1 -> -4
$

=== К $+oo$

Если число отрицательное, отбрасываем разряды. Если положительньое, то округляем к старшему числу. На числовой прямой, числа сдвигаются вправо, к $+oo$. Примеры:

$
  3.1 -> 3 wide -2.9 -> -2
$

=== К ближайшему четному

Если число ближе к младшему целому, округляем к нему. Если число ближе к старшему целому, округляем к нему. Если число находится ровно "посередине", округляем к тому целому числу, что четное. Примеры:

$
  1.2 -> 1 wide 2.6 -> 3 \
  -5.3 -> -5 wide -7.7 -> -8 \
  \
  3.5 -> 4 wide 2.5 -> 2 \
  -4.5 -> -4 wide -7.5 -> -8 \
$
